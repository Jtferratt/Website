---
title: 'Project 2: Modeling, Testing, and Classification'
author: "John Ferratt"
UTEID: "jtf948"
date: "2020-04-30"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

# Define class_diags function:
class_diag<-function(probs,truth){
  
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]

  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1
  
  #CALCULATE EXACT AUC
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}

knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
```

```{R}
# Calling necessary Libraries 
library("tidyverse")
library("dplyr")
library("ggplot2")
library("plotROC")

# Import Dataset
heart <- read.csv("heart.csv")
glimpse(heart)

# Check for Missing Values
heart %>% na.omit() %>% count()
```
## Creators of the dataset:
Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.
University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.
University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.
V.A. Medical Center, Long Beach and Cleveland Clinic Foundation: Robert Detrano, M.D., Ph.D.
Donor: David W. Aha (aha '@' ics.uci.edu) (714) 856-8779

## The source of the complete dataset can be found here: https://archive.ics.uci.edu/ml/datasets/Heart+Disease
While the abbreviated dataset used for the project can be found here: 
https://www.kaggle.com/volodymyrgavrysh/heart-disease/data# under user: VolodymyrGavrysh

## Introduction:
### This abbreviated dataset contains 303 complete observations of individuals who underwent experiments in Cleveland while the entire dataset has about 76 different attributes. Data on Individuals was taken regarding the following variables in effort to distinguish what would influence diagnosis of heart disease:

age = number of years the patient has lived (Age measured in years).
sex = Categorical variable denoting Male or Female for the patient (where Male = 1, Female= 0).
cp = Chest pain experienced by the patient (Denoted as typical= 0, Asymptotic= 1, nonanginal= 2, or nontypical= 3).
trestbps = Resting Blood Pressure measured in mmHG upon hospital admission. 
chol = The patient's serum cholesterol levels (mg/dl).
fbs = fasting blood sugar (Expressed in terms of whether or not the patient's fasting blood sugar was above 120 mg/dl, 0 = False, 1 = True).
restecg = resting electrocardiographic results (ranges 0 to 2).
thalach = The maximum heart rate the patient achieved in the hospital(beats per minute). 
exang = categorical variable denoting whether the patient experiences exercise induced angina (1=yes, 0=no).
oldpeak = ST depression read in the electrocardiogram induced by exercise relative to rest. 
slope = categorical variable representing the slope of the peak ST segment during patient exercise where 1= increase in slope, 2=no change/flat-slope, and 3= decrease in slope. 
ca = the number of major vessels colored by flouroscopy in the patient (denoted by the range of integers 0-3). 
thal = categorical variable representing the potential for Thalassemia in the patient where the body would carry less hemoglobin than normal. (Denoted as 1= normal, 2= fixed defect, and 3= reversable defect)
target = Binary classifier describing whether or not the Patient was diagnosed with Heart Disease (1 = yes, 0= no. )

```{R}
# Multivariate Normality Assumption Check
library(ggExtra)
library(mvtnorm)

# Assumption Testing
ggplot(heart, aes(x = age, y = trestbps)) +
  geom_point(alpha = .5) + geom_density_2d(h=2) + coord_fixed() + facet_wrap(~target)

cov(heart)

# MANOVA Results
heartmanova <- manova(cbind(age,trestbps,chol,thalach,oldpeak)~target, data= heart)
summary(heartmanova)

# ANOVA results
summary.aov(heartmanova)

# First Bonferroni Correction
0.05/6

# Post-hoc T-tests
pairwise.t.test(heart$age,heart$target,p.adj="none")
pairwise.t.test(heart$thalach,heart$target,p.adj="none")
pairwise.t.test(heart$oldpeak,heart$target,p.adj="none")

# Second Bonferroni Correction
0.05/9

# Type I Error (If Unadjusted)
1-((0.95)^9)
```
### A one-way MANOVA was conducted analyzing effects of presence of heart disease (diagnosed yes/no) on 5 numeric response/dependent variables (age, resting blood pressure, serum cholesterol, maximum heart rate, and ST depression). Merely looking at the multivariate normality plots shows that this assumption is not met. However, random sampling of hospital patients and the fact each patient represents an independent observation makes at least one assumption met. Some patients also possess an extremely high resting blood pressure and have high ST depressions (oldpeak) making outliers appear in the data and violating that assumption. Homogeneity of within-group covariances is also violated as merely looking at age does not show a result of 1 (instead it's ~82). Multicollinearity could be met as no immediate relationships are visible when plotted against one another. Despite these assumption violations, a MANOVA test was still carried out. 

### Not surprisingly, significant differences were found among those diagnosed with heart disease and those not diagnosed with heart disease for at least one of the dependent/response variables (age, resting blood pressure, serum cholesterol, ST depression, and maximum heart rate) (p-value= 2.2e-16, Pillai trace= 0.27846, pseudo F(5,297)= 22.924)

### One-way (univariate) ANOVA follow-up testing showed that age, maximum heart rate, and ST depression held at least one significant difference between the groups. Adjusting for bonferroni's correction, a significance level of (0.05/6 which equates to about 0.0083) was taken. (Age, p-value= 7.525e-05 < 0.0083, F= 16.117), (thalach, p-value=1.697e-14 < 0.0083, F=65.12), (oldpeak, p-value= 4.085e-15, F= 68.551)

### Post-hoc t-tests were then performed to analyze which Type of Patient (Diagnosed with heart disease or not) differed in the response variables age, ST depression, and maximum heart rate. With bonferroni's correction, the significance value was found to be (0.05/9 which equates to about 0.00556) because a total of 9 tests were taken (due to diagnosis only having 2 groups). Regardless, age (p-value= 7.5e-05), heart rate maximum (p-value= 1.7e-14), and ST depression (p-value= 4.1e-15) all fell below the bonferroni corrected level of significance of 0.00556 and thus the group of patients diagnosed with heart disease significantly differed in age, maximum heart rate, and ST depression from the patients not diagnosed with heart disease. 
### The type I error (if unadjusted) would have been 0.3697506. This would have been extremely high. 

```{R}
heart$cp <- as.factor(heart$cp)
heart$sex <- as.factor(heart$sex)
heart$fbs <- as.factor(heart$fbs)
heart$slope <- as.factor(heart$slope)
heart$thal <- as.factor(heart$thal)
heart$ca <- as.factor(heart$ca)

# Randomization Test
t.test(data=heart, age ~ target)

heart%>%group_by(target)%>%
  summarize(means=mean(age))%>%
  summarize(`mean_diff:`=diff(means))

set.seed(9001)
rand_dist1<-vector()

for(i in 1:5000){
heart1 <-data.frame(age=sample(heart$age), Diagnosis=heart$target) 
rand_dist1[i]<-mean(heart1[heart1$Diagnosis=="1",]$age)-
              mean(heart1[heart1$Diagnosis=="0",]$age)}

mean(rand_dist1 > 4.10448 | rand_dist1 < -4.10448)

{hist(rand_dist1,main="Null Distribution under t-statistic",ylab=""); abline(v = 4.10448,col="red")}
```
### A Randomization test was performed by randomizing the ages into a dataframe respective of whether the particular associate patient was diagnosed with heart disease in order to see if there was a difference in average age between the two categories- diagnosed with heart disease or not diagnosed. 

### Null Hypothesis (H0): The mean age for Patients diagnosed with heart disease is equal to the mean age for patients not diagnosed with heart disease. Thus, the difference in these means would be equal to 0. 

### Alternative Hypothesis (HA): The mean age for Patients diagnosed with heart disease and the mean age for patients not diagnosed with heart disease are not equal. Thus, the difference in these means would not be equal to 0. 

### Because the p-value of 0 is much less than the level of significance, we can reject the null hypothesis that the means are equal between the two groups. This is further supported by the fact that the parametric t-test gave a p-value of 5.781e-05 which is also extremely close to 0. (t-stat=4.0797, df=301).(Observed difference in means is 4.10448)

```{R}
# Linear Regression Model
library(sandwich)
library(lmtest)

heart <- heart %>% mutate(chol_c= chol - mean(chol), trestbps_c=trestbps - mean(trestbps),
                          exang=as.factor(exang))
heartfit <- lm(age ~ chol_c+trestbps_c+exang+trestbps_c:exang, data= heart)
summary(heartfit)

# Plotted Linear Model
heartlmplot<- heartfit %>% ggplot(aes(x= chol_c, y= trestbps_c, group= exang)) + geom_smooth(aes(color= exang), method= "lm") + geom_point(aes(color=exang)) + ggtitle("Linear Regression Model")
heartlmplot

# Assumption Checks

# Linearity
resids <- heartfit$residuals
fitvals <- heartfit$fitted.values
heartLinearity <- ggplot()+geom_point(aes(fitvals,resids))+geom_hline(yintercept=0, color='red')
heartLinearity

# Normality
heartQQ <- ggplot()+geom_qq(aes(sample=resids))+geom_qq_line(aes(sample=resids))
heartQQ
hearthist <- ggplot()+geom_histogram(aes(resids), bins=20)
hearthist

# Homoskedasticity
bptest(heartfit)

# Robust Standard Errors
coeftest(heartfit, vcov=vcovHC(heartfit))

# R-Squared Clarification 
(sum((heart$age-mean(heart$age))^2)-sum(heartfit$residuals^2))/sum((heart$age-mean(heart$age))^2)

```

### Intercept: The predicted age (in years) for a patient that has an average resting blood pressure(mmHg), has average serum cholesterol (mg/dl), and does not have exercise induced angina is 53.973903 years on average. (significant, p-value < 2e-16, t=89.951, df=299)

### trestbps_c: Controlling for average serum cholesterol, patients without exercise induced angina tend to be 0.172283 years older for every 1 unit increase in resting blood pressure (mmHg). (significant, p-value= 3.75e-06, t=4.713, df=299)

### chol_c: Controlling for average resting blood pressure (mmHg), patients without exercise induced angina tend to be 0.031834 years older for every 1 unit increase in serum cholesterol (mg/dl). (significant, p-value=0.00102, t=3.318, df=299)

### exang_Yes: Controlling for average resting blood pressure (mmHg) and average serum cholesterol (mg/dl), patients with exercise induced angina tend to be 1.375542 years older than those without exercise induced angina. (not significant, p-value=0.19231, t=1.307, df=299)

### trestbps_c:chol_c: Controlling for serum cholesterol (mg/dl), the slope for resting blood pressure on age is 0.102654 less for patients with exercise induced angina compared to those without exercise induced angina. (not significant, p-value= 0.07446, t-stat= -1.790, df=299)

### Because the data involves individual patients, each patient and their health issues represent independent observations. Furthermore, because each person responded to the exercise differently according to their own capabilities and health limitations, it can be assumed this is a random sample. According to the residuals plot, the residuals are scattered above and below the line throughout the line, showing no signs of fanning out, so the linearity assumption looks to have been met. Furthermore, the normality assumption appears to have been met according to the unimodal, zero-centered histogram distribution and the QQplot that mostly adheres to the y-intercept. Finally, according to the Breusch-Pagan test, with a p-value of 0.2985 that is greater than the level of significance of 0.05, we fail to reject the null hypothesis that the model is homoskedastic (BP = 4.8927, df = 4). 

### After running the t-test of coefficients, chol_c, trestbps_c, the intercept, and the interaction between trestbps_c and exang_Yes (trestbp_c:exang_Yes), all of the results were significant except for exang_yes which was not significant. This means that we would fail to reject the null hypothesis that heteroskedasticity is met for exang_Yes (p-value= 0.1899262, t-stat= 1.3138). However, because chol_c (p-value= 0.0005849, t-stat= 3.4759), trestbps_c (2.315e-06, t-stat= 4.8177), trestbps_c:exang_Yes (p-value= 0.0494332, t-stat= -1.9729), and the intercept (p-value= < 2.2e-16, t-stat= 88.9763) all were statistically significant, the equal variance assumption is fulfilled and we would reject the null hypothesis that heteroskedasticity is met, meaning that homoskedasticity is met instead. Thus, after robust standard errors, the interaction became significant, however, the categorical variable of exercise induced angina remained not significant. 

### The R-Squared value represents the amount of variation that could be explained by the linear regression model, `heartfit`. Thus, the proportion of variation in age that can be explained by `heartfit` is 0.1246. The adjusted R-Squared is slightly less at 0.1129 as seen in the model, but this is due to the multiple explanatory variables selected. 

```{R}
# Bootstrapped Standard Errors
set.seed(9001)

samp_resids <- replicate(5000, {
  fresh_resids <- sample(resids, replace= T)
  heart$new_y <- (fitvals + fresh_resids)
  fits <- lm(new_y ~ chol_c+trestbps_c+exang+trestbps_c:exang, data= heart)
  coef(fits)
})

samp_resids %>% t %>% as.data.frame %>% summarize_all(sd)

```
(Note that these observations are shown for one randomization, but the seed changes every time)

### The Intercept: (0.6066102) standard error did not drastically change from what it was in the robust standard error output as shown in paranthesis, instead it only decreases by about 0.0127889. The mean-centered serum cholesterol (chol_c, 0.0091587) standard error did not drastically change from what it was in the robust standard error output either as shown in paranthesis, instead it only increased by 0.00034124. The mean-centered resting blood pressure (trestbps_c, 0.0357602) standard error did not drastically change from what it was in the robust standard error output either as shown in paranthesis, instead it only increased by 0.00037172. Surprisingly, the variable, exang_Yes,(exang_Yes, 1.0469999) actually increased by 0.0012461 from what it had in the robust standard errors output and fineally the interaction between mean-centered resting blood pressure and having exercise induced angina (trestbps_c:exang_Yes, 0.0520325) standard error did not drastically change from what it was in the robust standard error output either as shown in paranthesis, instead it only increased by 0.00507481. Because these changes to the standard errors are so miniscule, we could expect similar outcomes where we would still reject the null hypothesis that heteroskedasticity is met except for in the exang_Yes response variable. 

```{R}
# Logistic Regression
heart$cp <- as.factor(heart$cp)
heartlogsfit <- glm(target ~ (cp+oldpeak+thalach+age+trestbps+chol), data=heart)
summary(heartlogsfit)
exp(coef(heartlogsfit))

# Confusion Matrix 
prob <- predict(heartlogsfit, type= "response")
pred <- ifelse(prob>0.5,1,0)
table(prediction=pred, truth=heart$target) %>% addmargins

# Generate Accuracy, Sensitivity, Specificity, PPV, and AUC
class_diag(prob, heart$target)
```
## Interpretation of coefficients: 

### Intercept: The odds of correctly predicting a patient with a chest pain rating of 0, an average ST depression, average maximum heart rate after exercise(bpm), average age(years), average resting blood pressure(mmHg), and an average serum cholesterol (mg/dl) to be diagnosed with heart disease would be 1.2977834. (not significant, p-value= 0.38138 > 0.05, t=0.877)

### cp1: Controlling for ST depression, maximum heart rate, age, resting blood pressure, and serum cholesterol, we would expect the odds of correctly predicting a patient with a chest pain rating of asymptotic(1) to be diagnosed with heart disease to be 1.3899784 times that of a chest pain rating of typical(0). (significant, p-value= 5.08e-06 < 0.05, t=4.647)

### cp2: Controlling for ST depression, maximum heart rate, age, resting blood pressure, and serum cholesterol, we would expect the odds of correctly predicting a patient with a chest pain rating of nonanginal(2) to be diagnosed with heart disease to be 1.4741431 times that of a chest pain rating of typical(0). (signigicant, p-value= 4.26e-11 < 0.05, t= 6.852)

### cp3: Controlling for ST depression, maximum heart rate, age, resting blood pressure, and serum cholesterol, the odds of correctly predicting a patient with a chest pain rating of nontypical(3) to be diagnosed with heart disease to be 1.4555471 times that of a chest pain rating of typical(0). (significant, p-value= 5.12e-05 < 0.05, t=4.111)

### oldpeak: Controlling for maximum heart rate, age, resting blood pressure, and serum cholesterol, we would expect that for every one unit increase in ST depression, the odds of correctly predicting a patient with a chest pain rating of typical(0) to be diagnosed with heart disease increases by a factor of 0.8989572. (significant, p-value= 1.87e-06 < 0.05, t=-4.865)

### thalach: Controlling for ST depression, age, resting blood pressure, and serum cholesterol, we would expect that for every one beat per minute increase in maximum heart rate, the odds of correctly predicting a patient with a chest pain rating of typical(0) to be diagnosed with heart disease increases by a factor of 1.0041013. (significant, p-value= 0.00072 < 0.05, t=3.418)

### age: Controlling for ST depression, resting blood pressure, maximum heart rate and serum cholesterol, we would expect that for every one year increase in age, the odds of correctly predicting a patient with a chest pain rating of typical(0) to be diagnosed with heart disease increases by a factor of 0.9986583. (not significant, p-value= 0.64435 > 0.05, t=-0.462)

### trestbps: Controlling for ST depression, age, maximum heart rate and serum cholesterol, we would expect that for every one mmHG increase in resting blood pressure, the odds of correctly predicting a patient with a chest pain rating of typical(0) to be diagnosed with heart disease increases by a factor of 0.9979532. (not significant, p-value= 0.13935 > 0.05, t=-1.482)

### chol: Controlling for ST depression, age, maximum heart rate and resting blood pressure, we would expect that for every one mg/dl increase in serum cholesterol, the odds of correctly predicting a patient with a chest pain rating of typical(0) to be diagnosed with heart disease increases by a factor of 0.9997180. (not significant, p-value= 0.53340 > 0.05, t=-0.624)

### The confusion matrix is contained in the code above. 

### The Accuracy of the model was found to be 0.7623762 and represents how much of the dataset the model classified correctly as diagnosed with heart disease or not. The specificity of 0.7028986	represents the proportion of patients correctly predicted as not diagnosed while the sensitivity of 0.8121212 represents the amount of patients the model classified correclty as having liver disease. The proportion of the population classified as diseased is 0.7657143 (the precision). Finally, the AUC which represents how well the model performs as a whole was found to be 0.8633729, which is Not great but still pretty good. These results show the model performed quite accurately but not entirely perfectly and there is still generous room for error. The fact that the sensitivity (true positive rate) is higher than the specificty (true negative rate) means the model's cutoff could be used to change borderline false positives and false negatives. 

```{R}
# Density of Log-Odds versus Binary Outcome (Heart Disease diagnosis)
heart2 <- heart %>% mutate(Diagnosis=ifelse(target=="1","Diseased","Normal"))

heart2$logit<-predict(heartlogsfit) #get predicted log-odds
heart2$outcome<-factor(heart2$Diagnosis,levels=c("Diseased","Normal"))
heartlogitplot <- ggplot(heart2,aes(logit, fill=outcome))+ geom_density(alpha=.3)+
  geom_vline(xintercept=0,lty=2) +
  ggtitle("Log-odds versus Binary Outcome Density")
heartlogitplot

```
```{R}
# ROC curve
heart4 <- heart %>% mutate(probcurve= predict(heartlogsfit, type= "response"))
heartROCplot <- ggplot(heart4) + geom_roc(aes(m= probcurve, d= target), n.cuts=0) +
  ggtitle("ROC Plot for Heart Disease Dataset Logistic Regression")
heartROCplot

# AUC Computation
calc_auc(heartROCplot)
```
According to the plot, we are able to calculate the AUC which was found to be 0.8633729. This AUC is regarded to be quite good, but not necessarily great. This represents the trade-off between Specificty and Sensitivity since increasing or decreasing the cutoff would allow for growth in one and a decrease in the other. An AUC between 0.8 and 0.9 is classified as good thus showing that this logistic regression model is a good predictor. 


```{R}
# 10-fold Cross-Validation 
set.seed(9001)
k=10

heart3<-heart[sample(nrow(heart)),] 
folds<-cut(seq(1:nrow(heart)),breaks=k,labels=F) 

diags<-NULL
for(i in 1:k){          
train<-heart3[folds!=i,] 
test<-heart3[folds==i,]  

truth<-test$target

fit<- glm(target~(cp+oldpeak+thalach+age+trestbps+chol), data=train, family="binomial")
probs<- predict(fit, newdata=test, type="response")

diags<-rbind(diags,class_diag(probs,truth)) 
}

summarize_all(diags,mean)
```
The Accuracy was found to be 0.7724731, while the sensitivity and specificity both decreased from the previous classification diagnostics of the logistic regression model (without cross-validation). The sensitivity is now 0.8535872 and the specificity is now 0.6762917. Output was also acquired for the PPV equating to 0.7732876. And finally, an AUC of 0.8358966 was obtained, suggesting more overfitting compared to the previous model.

```{R}
# LASSO Regression 
library("glmnet")
set.seed(9001)

heartLassoFit <- glm(target~(.), data=heart, family="binomial")
summary(heartLassoFit)

heartmatrix <- model.matrix(heartLassoFit)
heartmatrix <- heartmatrix[,-1]

heartresponse <- as.matrix(heart$target)

cv.lasso1 <- cv.glmnet(x=heartmatrix, y=heartresponse, family="binomial")
lasso1 <- glmnet(x=heartmatrix, y=heartresponse, family="binomial", alpha=1, lambda=cv.lasso1$lambda.1se)
coef(lasso1)

# Set Explanatory Dummy variables in a new dataset with the acquired LASSO Non-zero Coefficients

heart6 <- heart %>% mutate(sex1=ifelse(sex=="1",1,0), cp1=ifelse(cp=="1",1,0), cp2=ifelse(cp=="2",1,0), 
                           cp3=ifelse(cp=="3",1,0), exang1=ifelse(exang=="1",1,0),
                           slope1=ifelse(slope=="1",1,0), slope2=ifelse(slope=="2",1,0), 
                           ca1=ifelse(ca=="1",1,0), ca2=ifelse(ca=="2",1,0), ca3=ifelse(ca=="3",1,0),
                           thal2=ifelse(thal=="2",1,0), thal3=ifelse(thal=="3",1,0)) %>%
                    select(-sex, -cp, -chol, -fbs, -slope, -ca, -exang, -thal, -chol_c)
  
# 10-fold Out-of-Sample Cross Validation for LASSO Nonzero Coefficients

k=10

heart7<-heart6[sample(nrow(heart6)),] 
folds<-cut(seq(1:nrow(heart6)),breaks=k,labels=F) 

diags<-NULL
for(i in 1:k){          
train<-heart7[folds!=i,] 
test<-heart7[folds==i,]  

truth<-test$target

fit<- glm(target~(.), data=train, family="binomial")
probs<- predict(fit, newdata=test, type="response")

diags<-rbind(diags,class_diag(probs,truth)) 
}

summarize_all(diags,mean)
```
### Without considering the intercept, Coefficient Estimates that give a nonzero reading are:sex1(denoting male), cp1, cp2, cp3 (The varying degrees of chest pain not equal to typical), restecg(resting electrocardiograph results), thlach(maximum heart rate during exercise), exang1(presence of exercise induced angina), oldpeak (ST segment depression), slope1 (Where peak ST segment increases), slope2 (where peak ST segment stays constant), ca1, ca2, and ca3 (all representing highlighted portions from fluorscopy), thal2 (fixed effect of Thalessemia), and thal3 (reversible effect of Thalessemia). After running a LASSO on all the predictor variables, many predictors stood out to be significant and retained in the analysis as expressed prior. According to these new classification diagnostics run from the cross-validation of only the explanatory variables that had non-zero LASSO coefficients, an accuracy of 0.8553763 was obtained which is 0.0829032 higher than that from the cross-validation of the logistic regression from part 5 (0.7724731). The sensitivity was much higher (0.8885548) in the LASSO model. Furthermore a Specificity of 0.818295 was obtained and a PPV of 0.855508 was obtained. Lastly, the AUC, which shows the success of the model, was found to be 0.9124903, which is quite good. 

```{R, echo=F}
sessionInfo()
Sys.time()
Sys.info()
```
