---
title: "Python and R"
author: "John Ferratt"
date: '2020-05-15'
output:
  pdf_document: default
  html_document:
    df_print: paged
description: Detailing how Python and R can work together!
slug: python-and-r
tags: []
categories: []
---



<p><img src="/blog/2020-05-15-python-and-r_files/MyOldBoy.PNG" /></p>
<div id="python-and-r" class="section level1">
<h1>Python and R</h1>
<div id="r-is-a-very-handy-programming-language-for-analyzing-datasets-manipulating-data-and-creating-effective-plots-to-illustrate-relationships-between-variables-whereas-python-which-can-do-similar-things-is-very-slick-in-its-ability-to-create-functions-and-its-easily-readable-code-and-simplicity.-below-ive-taken-the-heart-dataset-in-python-and-using-the-reticulate-library-ive-been-able-to-use-that-dataset-in-r.-this-allowed-me-to-run-a-logistic-regression-on-the-data-and-using-lasso-ive-selected-the-variables-that-have-a-significant-effect-on-whether-or-not-a-patient-was-predicted-to-have-heart-disease-for-more-information-see-the-modeling-project-under-the-projects-tab-to-obtain-an-roc-plot-of-which-i-used-to-calculate-the-area-under-the-curve-auc.-this-could-then-be-used-to-determine-how-effective-our-model-is." class="section level2">
<h2>R is a very handy programming language for analyzing datasets, manipulating data and creating effective plots to illustrate relationships between variables whereas Python which can do similar things is very slick in its ability to create functions and its easily readable code and simplicity. Below, I’ve taken the <code>heart</code> dataset in python and using the Reticulate library, I’ve been able to use that dataset in R. This allowed me to run a logistic regression on the data, and using LASSO, I’ve selected the variables that have a significant effect on whether or not a patient was predicted to have heart disease (For more information, see the Modeling project under the Projects Tab) to obtain an ROC plot of which I used to calculate the Area-under-the-curve (AUC). This could then be used to determine how effective our model is.</h2>
<pre class="python"><code>import re
import pandas as pd
heart = pd.read_csv(&quot;heart.csv&quot;)</code></pre>
<pre class="r"><code>library(&quot;reticulate&quot;)
library(&quot;lmtest&quot;)</code></pre>
<pre><code>## Loading required package: zoo</code></pre>
<pre><code>## 
## Attaching package: &#39;zoo&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     as.Date, as.Date.numeric</code></pre>
<pre class="r"><code>library(&quot;tidyverse&quot;)</code></pre>
<pre><code>## ── Attaching packages ──────────────────────────────────────────────────────── tidyverse 1.3.0 ──</code></pre>
<pre><code>## ✓ ggplot2 3.2.1     ✓ purrr   0.3.3
## ✓ tibble  2.1.3     ✓ dplyr   0.8.4
## ✓ tidyr   1.0.2     ✓ stringr 1.4.0
## ✓ readr   1.3.1     ✓ forcats 0.5.0</code></pre>
<pre><code>## ── Conflicts ─────────────────────────────────────────────────────────── tidyverse_conflicts() ──
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code>library(&quot;plotROC&quot;)
library(&quot;glmnet&quot;)</code></pre>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## 
## Attaching package: &#39;Matrix&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:tidyr&#39;:
## 
##     expand, pack, unpack</code></pre>
<pre><code>## Loaded glmnet 3.0-2</code></pre>
<pre class="r"><code>heart &lt;- py$heart

# Define class_diags function:
class_diag&lt;-function(probs,truth){
  
  tab&lt;-table(factor(probs&gt;.5,levels=c(&quot;FALSE&quot;,&quot;TRUE&quot;)),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]

  if(is.numeric(truth)==FALSE &amp; is.logical(truth)==FALSE) truth&lt;-as.numeric(truth)-1
  
  #CALCULATE EXACT AUC
  ord&lt;-order(probs, decreasing=TRUE)
  probs &lt;- probs[ord]; truth &lt;- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup&lt;-c(probs[-1]&gt;=probs[-length(probs)], FALSE)
  TPR&lt;-c(0,TPR[!dup],1); FPR&lt;-c(0,FPR[!dup],1)
  
  n &lt;- length(TPR)
  auc&lt;- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}

heart$cp &lt;- as.factor(heart$cp)
heart$sex &lt;- as.factor(heart$sex)
heart$fbs &lt;- as.factor(heart$fbs)
heart$slope &lt;- as.factor(heart$slope)
heart$thal &lt;- as.factor(heart$thal)
heart$ca &lt;- as.factor(heart$ca)
heart &lt;- heart %&gt;% mutate(chol_c= chol - mean(chol), trestbps_c=trestbps - mean(trestbps),exang=as.factor(exang))


heartLassoFit &lt;- glm(target~(.), data=heart, family=&quot;binomial&quot;)
summary(heartLassoFit)</code></pre>
<pre><code>## 
## Call:
## glm(formula = target ~ (.), family = &quot;binomial&quot;, data = heart)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.9459  -0.2917   0.1024   0.4479   3.1401  
## 
## Coefficients: (2 not defined because of singularities)
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  0.256315   3.717325   0.069 0.945028    
## age          0.027711   0.025461   1.088 0.276436    
## sex1        -1.845598   0.570225  -3.237 0.001210 ** 
## cp1          0.872344   0.578449   1.508 0.131535    
## cp2          2.017603   0.530174   3.806 0.000141 ***
## cp3          2.427691   0.718961   3.377 0.000734 ***
## trestbps    -0.026755   0.011778  -2.272 0.023108 *  
## chol        -0.004489   0.004202  -1.068 0.285391    
## fbs1         0.461956   0.589685   0.783 0.433395    
## restecg      0.398460   0.383928   1.038 0.299339    
## thalach      0.020396   0.011853   1.721 0.085297 .  
## exang1      -0.778793   0.451888  -1.723 0.084813 .  
## oldpeak     -0.416509   0.240005  -1.735 0.082667 .  
## slope1      -0.756969   0.873155  -0.867 0.385978    
## slope2       0.705157   0.941443   0.749 0.453847    
## ca1         -2.356771   0.526311  -4.478 7.54e-06 ***
## ca2         -3.462666   0.811700  -4.266 1.99e-05 ***
## ca3         -2.294901   0.935058  -2.454 0.014116 *  
## ca4          1.240056   1.704808   0.727 0.466989    
## thal1        2.636985   2.705956   0.975 0.329803    
## thal2        2.372031   2.618241   0.906 0.364955    
## thal3        0.934193   2.622063   0.356 0.721630    
## chol_c             NA         NA      NA       NA    
## trestbps_c         NA         NA      NA       NA    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 417.64  on 302  degrees of freedom
## Residual deviance: 180.01  on 281  degrees of freedom
## AIC: 224.01
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<pre class="r"><code>heartmatrix &lt;- model.matrix(heartLassoFit)
heartmatrix &lt;- heartmatrix[,-1]

heartresponse &lt;- as.matrix(heart$target)

cv.lasso1 &lt;- cv.glmnet(x=heartmatrix, y=heartresponse, family=&quot;binomial&quot;)
lasso1 &lt;- glmnet(x=heartmatrix, y=heartresponse, family=&quot;binomial&quot;, alpha=1, lambda=cv.lasso1$lambda.1se)
coef(lasso1)</code></pre>
<pre><code>## 24 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                        s0
## (Intercept)  0.2759850905
## age          .           
## sex1        -0.6510888890
## cp1          0.3566244751
## cp2          0.9776758666
## cp3          0.7872374641
## trestbps    -0.0043528443
## chol         .           
## fbs1         .           
## restecg      0.0779083641
## thalach      0.0111909936
## exang1      -0.6578457834
## oldpeak     -0.3219827701
## slope1      -0.4305644603
## slope2       0.2161553260
## ca1         -1.1449361967
## ca2         -1.5499626571
## ca3         -1.0591243029
## ca4          .           
## thal1        .           
## thal2        0.5020682632
## thal3       -0.7323821315
## chol_c       .           
## trestbps_c  -0.0001739217</code></pre>
<pre class="r"><code># Set Explanatory Dummy variables in a new dataset with the acquired LASSO Non-zero Coefficients

heart6 &lt;- heart %&gt;% mutate(sex1=ifelse(sex==&quot;1&quot;,1,0), cp1=ifelse(cp==&quot;1&quot;,1,0), cp2=ifelse(cp==&quot;2&quot;,1,0), 
                           cp3=ifelse(cp==&quot;3&quot;,1,0), exang1=ifelse(exang==&quot;1&quot;,1,0),
                           slope1=ifelse(slope==&quot;1&quot;,1,0), slope2=ifelse(slope==&quot;2&quot;,1,0), 
                           ca1=ifelse(ca==&quot;1&quot;,1,0), ca2=ifelse(ca==&quot;2&quot;,1,0), ca3=ifelse(ca==&quot;3&quot;,1,0),
                           thal2=ifelse(thal==&quot;2&quot;,1,0), thal3=ifelse(thal==&quot;3&quot;,1,0)) %&gt;%
                    select(-sex, -cp, -chol, -fbs, -slope, -ca, -exang, -thal, -chol_c)
  
# 10-fold Out-of-Sample Cross Validation for LASSO Nonzero Coefficients

k=10

heart7&lt;-heart6[sample(nrow(heart6)),] 
folds&lt;-cut(seq(1:nrow(heart6)),breaks=k,labels=F) 

diags&lt;-NULL
for(i in 1:k){          
train&lt;-heart7[folds!=i,] 
test&lt;-heart7[folds==i,]  

truth&lt;-test$target

fit&lt;- glm(target~(.), data=train, family=&quot;binomial&quot;)
probs&lt;- predict(fit, newdata=test, type=&quot;response&quot;)

diags&lt;-rbind(diags,class_diag(probs,truth)) 
}</code></pre>
<pre><code>## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading

## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading

## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading

## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading

## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading

## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading

## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading

## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading

## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading

## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading</code></pre>
<pre class="r"><code>summarize_all(diags,mean)</code></pre>
<pre><code>##         acc      sens      spec       ppv       auc
## 1 0.8382796 0.8729458 0.8003544 0.8439228 0.9150978</code></pre>
<pre class="r"><code>heart4 &lt;- heart %&gt;% mutate(probcurve= predict(heartLassoFit, type= &quot;response&quot;))
heartROCplot &lt;- ggplot(heart4) + geom_roc(aes(m= probcurve, d= target), n.cuts=0) +
  ggtitle(&quot;ROC Plot for Heart Disease Dataset Logistic Regression&quot;)
heartROCplot</code></pre>
<p><img src="/blog/2020-05-15-python-and-r_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code># AUC Computation
auc &lt;- calc_auc(heartROCplot) %&gt;% pull(AUC)
auc</code></pre>
<pre><code>## [1] 0.945762</code></pre>
<p>Now if we take the AUC and run it back through python, we can set up a function with a set of conditional statements to describe the AUC obtained from the logistic regression.</p>
<pre class="python"><code>def rating(number):
    if number &lt;= 0.5:
        return &quot;very bad&quot;
    elif number &lt;= 0.6:
        return &quot;bad&quot;
    elif number &lt;= 0.7:
        return &quot;poor&quot;
    elif number &lt;= 0.8:
        return &quot;fair&quot;
    elif number &lt;= 0.9:
        return &quot;good&quot;
    elif number &lt;= 1.0:
        return &quot;great&quot;
    
result = rating(r.auc)
print(&quot;The AUC of&quot;,r.auc,&quot;is considered&quot;,result)</code></pre>
<pre><code>## The AUC of 0.9457619675010972 is considered great</code></pre>
</div>
</div>
